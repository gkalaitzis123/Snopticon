{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import threading\n",
    "from flask import Flask, Response, render_template_string\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"s1.pt\")\n",
    "\n",
    "# Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Shared frames and locks\n",
    "frames = {\"CAM 1\": None, \"CAM 2\": None}\n",
    "locks = {\"CAM 1\": threading.Lock(), \"CAM 2\": threading.Lock()}\n",
    "\n",
    "# HTML Template for dual camera view\n",
    "html_template = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>YOLOv8 Snake Detection</title>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <style>\n",
    "        body {\n",
    "            background: #111;\n",
    "            color: white;\n",
    "            font-family: sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "        }\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            padding: 20px;\n",
    "            font-size: 28px;\n",
    "        }\n",
    "        .cam-box {\n",
    "            background: #222;\n",
    "            padding: 10px;\n",
    "            margin: 20px auto;\n",
    "            max-width: 960px;\n",
    "            border-radius: 12px;\n",
    "            box-shadow: 0 0 10px rgba(255,255,255,0.1);\n",
    "        }\n",
    "        .cam-box h3 {\n",
    "            margin: 0 0 10px 0;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .cam-box img {\n",
    "        display: block;\n",
    "        border-radius: 10px;\n",
    "        width: auto;\n",
    "        height: auto;\n",
    "        max-width: 100%;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>üêç YOLOv8 Snake Detection Feed</h1>\n",
    "\n",
    "    <div class=\"cam-box\">\n",
    "        <h3>CAM 1</h3>\n",
    "        <img src=\"{{ url_for('video_feed', cam_name='CAM 1') }}\">\n",
    "    </div>\n",
    "\n",
    "    <div class=\"cam-box\">\n",
    "        <h3>CAM 2</h3>\n",
    "        <img src=\"{{ url_for('video_feed', cam_name='CAM 2') }}\">\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def draw_overlay(frame, cam_name):\n",
    "    hour = datetime.now().hour\n",
    "    mode = \"Night\" if hour >= 22 or hour < 9 else \"Day\"\n",
    "    datetime_str = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "    overlay_lines = [f\"{cam_name}\", datetime_str, f\"Mode: {mode}\"]\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.6\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "    y_offset = 25\n",
    "\n",
    "    for i, line in enumerate(overlay_lines):\n",
    "        size = cv2.getTextSize(line, font, scale, thickness)[0]\n",
    "        x = frame.shape[1] - size[0] - 10\n",
    "        y = (i + 1) * y_offset\n",
    "        cv2.putText(frame, line, (x, y), font, scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_and_update(cam_id, cam_name):\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        results = model(frame, verbose=False)[0]\n",
    "\n",
    "        for box in results.boxes:\n",
    "            cls = int(box.cls)\n",
    "            label = model.names[cls]\n",
    "            conf = float(box.conf)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        with locks[cam_name]:\n",
    "            frames[cam_name] = frame.copy()\n",
    "\n",
    "def generate_stream(cam_name):\n",
    "    while True:\n",
    "        with locks[cam_name]:\n",
    "            frame = frames[cam_name]\n",
    "        if frame is None:\n",
    "            continue\n",
    "        _, jpeg = cv2.imencode('.jpg', frame)\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(html_template)\n",
    "\n",
    "@app.route('/video_feed/<cam_name>')\n",
    "def video_feed(cam_name):\n",
    "    return Response(generate_stream(cam_name),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Start each camera stream in its own thread\n",
    "    t1 = threading.Thread(target=detect_and_update, args=(0, \"CAM 1\"), daemon=True)\n",
    "    t2 = threading.Thread(target=detect_and_update, args=(1, \"CAM 2\"), daemon=True)\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    app.run(host='0.0.0.0', port=5000, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3b7f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n",
      "[CAM 2] ? Failed to access camera.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.140:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CAM 1] ?? Watching for motion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Apr/2025 23:20:26] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Apr/2025 23:20:26] \"GET /video_feed/CAM%201 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Apr/2025 23:20:26] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-21 (monitor_camera):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\gkrul\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\gkrul\\AppData\\Local\\Temp\\ipykernel_20552\\3843434059.py\", line 147, in monitor_camera\n",
      "  File \"C:\\Users\\gkrul\\AppData\\Local\\Temp\\ipykernel_20552\\3843434059.py\", line 98, in draw_yolo_predictions\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 182, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 543, in predict\n",
      "    self.predictor.setup_model(model=self.model, verbose=is_cli)\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 380, in setup_model\n",
      "    self.model = AutoBackend(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py\", line 162, in __init__\n",
      "    model = weights.to(device)\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1343, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 262, in _apply\n",
      "    self = super()._apply(fn)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 902, in _apply\n",
      "    for module in self.children():\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2725, in children\n",
      "    for _name, module in self.named_children():\n",
      "  File \"c:\\Users\\gkrul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2743, in named_children\n",
      "    for name, module in self._modules.items():\n",
      "RuntimeError: OrderedDict mutated during iteration\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from threading import Thread, Lock\n",
    "from flask import Flask, Response, render_template_string\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"s1.pt\")  # Change to absolute path if needed\n",
    "\n",
    "# Settings\n",
    "fps = 15.0\n",
    "frame_size = (1260, 720)\n",
    "\n",
    "app = Flask(__name__)\n",
    "frames = {\"CAM 1\": None, \"CAM 2\": None}\n",
    "locks = {\"CAM 1\": Lock(), \"CAM 2\": Lock()}\n",
    "\n",
    "html_template = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Snake Stream</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: sans-serif;\n",
    "            background-color: #f0f0f0;\n",
    "            margin: 0;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        h2 {\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            flex-wrap: wrap;\n",
    "            gap: 20px;\n",
    "        }\n",
    "        .cam-box {\n",
    "            background: white;\n",
    "            padding: 10px;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 0 10px rgba(0,0,0,0.2);\n",
    "        }\n",
    "        .cam-box h3 {\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        .cam-box img {\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            width: 960px;\n",
    "            border-radius: 8px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h2>Live Camera Feeds</h2>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"cam-box\">\n",
    "            <h3>CAM 1</h3>\n",
    "            <img src=\"{{ url_for('video_feed', cam_name='CAM 1') }}\">\n",
    "        </div>\n",
    "        <div class=\"cam-box\">\n",
    "            <h3>CAM 2</h3>\n",
    "            <img src=\"{{ url_for('video_feed', cam_name='CAM 2') }}\">\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def adjust_brightness(cap):\n",
    "    hour = datetime.now().hour\n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 0.2 if hour >= 22 or hour < 9 else 1.0)\n",
    "    return \"night\" if hour >= 22 or hour < 9 else \"day\"\n",
    "\n",
    "def draw_timestamp_overlay(frame, brightness_mode, cam_name):\n",
    "    now = datetime.now()\n",
    "    datetime_str = now.strftime(\"%m/%d/%y %H:%M:%S\")\n",
    "    label = \"Day\" if brightness_mode == \"day\" else \"Night\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.6\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "    lines = [cam_name.upper(), datetime_str, label]\n",
    "    y_offset = 25\n",
    "    for i, line in enumerate(lines):\n",
    "        size = cv2.getTextSize(line, font, scale, thickness)[0]\n",
    "        x = frame.shape[1] - size[0] - 10\n",
    "        y = (i + 1) * y_offset\n",
    "        cv2.putText(frame, line, (x, y), font, scale, color, thickness, cv2.LINE_AA)\n",
    "    return frame\n",
    "    \n",
    "def draw_yolo_predictions(frame):\n",
    "    results = model(frame, verbose=False)[0]\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls)\n",
    "        label = model.names[cls]\n",
    "        conf = float(box.conf)\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "def monitor_camera(device_path, cam_name):\n",
    "    cap = cv2.VideoCapture(device_path)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_size[0])\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_size[1])\n",
    "    cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"[{cam_name}] ? Failed to access camera.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_gray = cv2.GaussianBlur(prev_gray, (21, 21), 0)\n",
    "\n",
    "    print(f\"[{cam_name}] ?? Watching for motion...\")\n",
    "\n",
    "    while True:\n",
    "        brightness_mode = adjust_brightness(cap)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            time.sleep(1)\n",
    "            cap = cv2.VideoCapture(device_path)\n",
    "            continue\n",
    "\n",
    "        # Motion detection (can be used for other logic)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        delta = cv2.absdiff(prev_gray, gray)\n",
    "        thresh = cv2.threshold(delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        prev_gray = gray\n",
    "\n",
    "        # Add timestamp\n",
    "        frame = draw_timestamp_overlay(frame, brightness_mode, cam_name)\n",
    "\n",
    "        # Run YOLO detection and draw boxes\n",
    "        frame = draw_yolo_predictions(frame)\n",
    "\n",
    "        # Update Flask stream\n",
    "        with locks[cam_name]:\n",
    "            frames[cam_name] = frame.copy()\n",
    "\n",
    "def generate_stream(cam_name):\n",
    "    while True:\n",
    "        with locks[cam_name]:\n",
    "            frame = frames.get(cam_name)\n",
    "            if frame is None:\n",
    "                continue\n",
    "            _, jpeg = cv2.imencode('.jpg', frame)\n",
    "        time.sleep(0.03)  # ~30 FPS update\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "                   \n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template_string(html_template)\n",
    "\n",
    "@app.route('/video_feed/<cam_name>')\n",
    "def video_feed(cam_name):\n",
    "    return Response(generate_stream(cam_name), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "# Start threads (Windows: use integers for webcams)\n",
    "thread1 = Thread(target=monitor_camera, args=(0, \"CAM 1\"))\n",
    "thread2 = Thread(target=monitor_camera, args=(1, \"CAM 2\"))  # Optional second cam\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Run Flask app\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, threaded=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
